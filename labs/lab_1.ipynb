{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44f4d959",
   "metadata": {},
   "source": [
    "# Introduction to Semantic Kernel Agents\n",
    "\n",
    "Welcome to this workshop on Semantic Kernel (SK) agents! In this notebook, we'll explore how to create, configure, and use agents with the Semantic Kernel framework.\n",
    "\n",
    "## What You'll Learn\n",
    "- What agents are in Semantic Kernel\n",
    "- How to create and configure different types of agents\n",
    "- Basic and advanced interaction patterns with agents\n",
    "- How to integrate plugins and functions with agents\n",
    "- Multi-agent systems and orchestration\n",
    "\n",
    "Let's start by setting up our environment and understanding the foundational concepts of Semantic Kernel agents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9f281d",
   "metadata": {},
   "source": [
    "## 1. Introduction to Semantic Kernel Agents\n",
    "\n",
    "### What are agents in Semantic Kernel?\n",
    "\n",
    "In Semantic Kernel, an **agent** is a specialized component that can interact with Large Language Models (LLMs), process conversations, make decisions, and potentially execute code or call functions. Unlike simple prompt-based interactions, agents maintain state, follow instructions, and can engage in multi-turn conversations to accomplish tasks.\n",
    "\n",
    "At their core, agents are designed to:\n",
    "- Process user inputs and generate contextual responses\n",
    "- Maintain conversation history and context\n",
    "- Execute functions when appropriate (function calling)\n",
    "- Work independently or collaborate with other agents\n",
    "\n",
    "\n",
    "### Agent Architecture in Semantic Kernel\n",
    "\n",
    "Key components in the agent architecture:\n",
    "\n",
    "1. **Kernel**: The core orchestration engine that connects agents to AI services and functions\n",
    "2. **AI Service**: The underlying LLM that powers the agent (like Azure OpenAI, OpenAI)\n",
    "3. **Chat History**: Maintains the conversation context over multiple turns\n",
    "4. **Plugins/Functions**: Optional extensions that allow the agent to perform specific tasks\n",
    "\n",
    "### Types of Agents in Semantic Kernel\n",
    "\n",
    "Semantic Kernel primarily offers two types of agents:\n",
    "\n",
    "1. **ChatCompletionAgent**\n",
    "   - Lightweight agent that uses your kernel's chat completion service\n",
    "   - Good for simple conversational tasks\n",
    "   - Manages chat history locally\n",
    "\n",
    "2. **OpenAIAssistantAgent / AzureAssistantAgent**\n",
    "   - Uses OpenAI's Assistant API\n",
    "   - Maintains conversation state remotely as \"threads\"\n",
    "   - Supports advanced features like code interpretation and file searching\n",
    "   - Requires explicit thread management\n",
    "\n",
    "Let's first install the necessary packages to work with Semantic Kernel agents:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92b2bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ff8f44",
   "metadata": {},
   "source": [
    "Now, let's set up our environment by loading environment variables and importing the necessary modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d152f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Import Semantic Kernel components\n",
    "import semantic_kernel as sk\n",
    "from semantic_kernel.agents import ChatCompletionAgent\n",
    "from semantic_kernel.connectors.ai.open_ai import (\n",
    "    AzureChatCompletion,\n",
    "    OpenAIChatCompletion,\n",
    ")\n",
    "from semantic_kernel.contents import ChatHistory, ChatMessageContent\n",
    "from semantic_kernel.contents.utils.author_role import AuthorRole\n",
    "from semantic_kernel.functions import KernelArguments\n",
    "from semantic_kernel.connectors.ai import FunctionChoiceBehavior\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a97966",
   "metadata": {},
   "source": [
    "For this workshop, we'll need to set up our environment variables with either Azure OpenAI or OpenAI credentials. You can create a `.env` file in the same directory as this notebook with the following variables:\n",
    "\n",
    "```\n",
    "AZURE_OPENAI_ENDPOINT='[YOUR_ENDPOINT]'\n",
    "AZURE_OPENAI_API_KEY='[YOUR_API_KEY]'\n",
    "AZURE_OPENAI_MODEL_DEPLOYMENT_NAME='gpt-4o'\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32307ce",
   "metadata": {},
   "source": [
    "## 2. Setting Up Your Environment\n",
    "\n",
    "Now that we understand what agents are and have imported the necessary modules, let's begin by creating our first kernel instance and configuring the environment properly.\n",
    "\n",
    "### Creating a Kernel Instance\n",
    "\n",
    "The `Kernel` is the central orchestration component in Semantic Kernel. It manages AI services, plugins, and other resources that agents need to function. Let's now create a helper function that will configure a kernel with the appropriate AI service based on the available credentials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0262a3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_id = 'agent'\n",
    "def create_kernel_with_service(service_id):\n",
    "    kernel = sk.Kernel()\n",
    "    kernel.add_service(\n",
    "        AzureChatCompletion(\n",
    "            service_id=service_id,\n",
    "            deployment_name=os.getenv(\"AZURE_OPENAI_MODEL_DEPLOYMENT_NAME\"),\n",
    "            api_key=os.getenv('AZURE_OPENAI_API_KEY'),\n",
    "            endpoint=os.getenv('AZURE_OPENAI_ENDPOINT')\n",
    "        )\n",
    "    )\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5885f19",
   "metadata": {},
   "source": [
    "Now let's create our first kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584efa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = create_kernel_with_service(service_id=\"chat-completion\")\n",
    "print(\"Kernel created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dd3dfe",
   "metadata": {},
   "source": [
    "### Understanding Service Configuration\n",
    "\n",
    "When adding an AI service to the kernel, we specified a `service_id`. This ID is important because:\n",
    "\n",
    "1. It allows you to add multiple services to the same kernel\n",
    "2. You can selectively use different services for different agents\n",
    "3. It helps organize and identify your services\n",
    "\n",
    "If you need specific execution settings for your AI service (like temperature, top-p, or function calling behavior), you can retrieve and modify them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44efdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the execution settings for our service\n",
    "settings = kernel.get_prompt_execution_settings_from_service_id(\n",
    "    service_id=\"chat-completion\"\n",
    ")\n",
    "\n",
    "# Configure settings\n",
    "settings.temperature = 0.7\n",
    "settings.function_choice_behavior = FunctionChoiceBehavior.Auto()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a19c85",
   "metadata": {},
   "source": [
    "### Exercise: Create Multiple Services in a Kernel\n",
    "\n",
    "In this exercise, try creating a kernel with two different AI services with different configurations. This will be useful when we want to use different services for different agents or functions.\n",
    "\n",
    "Your task:\n",
    "1. Create a new kernel\n",
    "2. Add two services with different service IDs (e.g., \"creative\" and \"precise\")\n",
    "3. Configure the \"creative\" service with higher temperature (e.g., 0.8)\n",
    "4. Configure the \"precise\" service with lower temperature (e.g., 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8c480f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize your kernel\n",
    "\n",
    "# Add first service - creative with higher temperature\n",
    "\n",
    "# Add second service - precise with lower temperature\n",
    "\n",
    "# Configure the settings for each service\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc602c9e",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to see solution</summary>\n",
    "\n",
    "```python\n",
    "# Create a new kernel for multiple services\n",
    "multi_service_kernel = sk.Kernel()\n",
    "\n",
    "# Add first service - creative with higher temperature\n",
    "\n",
    "multi_service_kernel.add_service(\n",
    "    AzureChatCompletion(\n",
    "        service_id=\"creative\",\n",
    "        deployment_name=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),\n",
    "        endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "        api_key=os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add second service - precise with lower temperature\n",
    "multi_service_kernel.add_service(\n",
    "    AzureChatCompletion(\n",
    "        service_id=\"precise\",\n",
    "        deployment_name=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),\n",
    "        endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "        api_key=os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Configure the settings for each service\n",
    "creative_settings = multi_service_kernel.get_prompt_execution_settings_from_service_id(service_id=\"creative\")\n",
    "creative_settings.temperature = 0.8\n",
    "print(f\"Creative service temperature: {creative_settings.temperature}\")\n",
    "\n",
    "precise_settings = multi_service_kernel.get_prompt_execution_settings_from_service_id(service_id=\"precise\")\n",
    "precise_settings.temperature = 0.2\n",
    "print(f\"Precise service temperature: {precise_settings.temperature}\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa2ca98",
   "metadata": {},
   "source": [
    "### Key Takeaways\n",
    "\n",
    "In this section, we've learned how to:\n",
    "\n",
    "1. **Set up our environment** with necessary imports and credentials\n",
    "2. **Create a kernel** as the foundation for our agents\n",
    "3. **Configure AI services** with specific IDs and settings\n",
    "4. **Manage execution settings** to control how the AI generates responses\n",
    "\n",
    "In the next section, we'll create our first agent using the kernel we've just configured."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994f8098",
   "metadata": {},
   "source": [
    "## 3. Your First Agent: ChatCompletionAgent\n",
    "\n",
    "Now that we have our kernel and services set up, let's create our first agent. We'll start with the `ChatCompletionAgent`, which is a simple yet powerful agent that leverages the chat completion capabilities of large language models.\n",
    "\n",
    "### Creating a Basic Agent\n",
    "\n",
    "To create a `ChatCompletionAgent`, we need to provide:\n",
    "1. A kernel with a configured chat service\n",
    "2. Instructions that define the agent's behavior\n",
    "3. Optional parameters like a name and execution settings\n",
    "\n",
    "Let's create a simple assistant agent:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
