{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44f4d959",
   "metadata": {},
   "source": [
    "# Introduction to Semantic Kernel Agents\n",
    "\n",
    "Welcome to this workshop on Semantic Kernel (SK) agents! In this notebook, we'll explore how to create, configure, and use agents with the Semantic Kernel framework.\n",
    "\n",
    "## What You'll Learn\n",
    "- What agents are in Semantic Kernel\n",
    "- How to create and configure different types of agents\n",
    "- Basic and advanced interaction patterns with agents\n",
    "- How to integrate plugins and functions with agents\n",
    "- Multi-agent systems and orchestration\n",
    "\n",
    "Let's start by setting up our environment and understanding the foundational concepts of Semantic Kernel agents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9f281d",
   "metadata": {},
   "source": [
    "## 1. Introduction to Semantic Kernel Agents\n",
    "\n",
    "### What are agents in Semantic Kernel?\n",
    "\n",
    "In Semantic Kernel, an **agent** is a specialized component that can interact with Large Language Models (LLMs), process conversations, make decisions, and potentially execute code or call functions. Unlike simple prompt-based interactions, agents maintain state, follow instructions, and can engage in multi-turn conversations to accomplish tasks.\n",
    "\n",
    "At their core, agents are designed to:\n",
    "- Process user inputs and generate contextual responses\n",
    "- Maintain conversation history and context\n",
    "- Execute functions when appropriate (function calling)\n",
    "- Work independently or collaborate with other agents\n",
    "\n",
    "\n",
    "### Agent Architecture in Semantic Kernel\n",
    "\n",
    "Key components in the agent architecture:\n",
    "\n",
    "1. **Kernel**: The core orchestration engine that connects agents to AI services and functions\n",
    "2. **AI Service**: The underlying LLM that powers the agent (like Azure OpenAI, OpenAI)\n",
    "3. **Chat History**: Maintains the conversation context over multiple turns\n",
    "4. **Plugins/Functions**: Optional extensions that allow the agent to perform specific tasks\n",
    "\n",
    "### Types of Agents in Semantic Kernel\n",
    "\n",
    "Semantic Kernel primarily offers two types of agents:\n",
    "\n",
    "1. **ChatCompletionAgent**\n",
    "   - Lightweight agent that uses your kernel's chat completion service\n",
    "   - Good for simple conversational tasks\n",
    "   - Manages chat history locally\n",
    "\n",
    "2. **OpenAIAssistantAgent / AzureAssistantAgent**\n",
    "   - Uses OpenAI's Assistant API\n",
    "   - Maintains conversation state remotely as \"threads\"\n",
    "   - Supports advanced features like code interpretation and file searching\n",
    "   - Requires explicit thread management\n",
    "\n",
    "Let's first install the necessary packages to work with Semantic Kernel agents:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92b2bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ff8f44",
   "metadata": {},
   "source": [
    "Now, let's set up our environment by loading environment variables and importing the necessary modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d152f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Import Semantic Kernel components\n",
    "import semantic_kernel as sk\n",
    "from semantic_kernel.agents import ChatCompletionAgent\n",
    "from semantic_kernel.connectors.ai.open_ai import (\n",
    "    AzureChatCompletion,\n",
    "    OpenAIChatCompletion,\n",
    ")\n",
    "from semantic_kernel.contents import ChatHistory, ChatMessageContent\n",
    "from semantic_kernel.contents.utils.author_role import AuthorRole\n",
    "from semantic_kernel.functions import KernelArguments\n",
    "from semantic_kernel.connectors.ai import FunctionChoiceBehavior\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a97966",
   "metadata": {},
   "source": [
    "For this workshop, we'll need to set up our environment variables with either Azure OpenAI or OpenAI credentials. You can create a `.env` file in the same directory as this notebook with the following variables:\n",
    "\n",
    "```\n",
    "AZURE_OPENAI_ENDPOINT='[YOUR_ENDPOINT]'\n",
    "AZURE_OPENAI_API_KEY='[YOUR_API_KEY]'\n",
    "AZURE_OPENAI_MODEL_DEPLOYMENT_NAME='gpt-4o'\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32307ce",
   "metadata": {},
   "source": [
    "## 2. Setting Up Your Environment\n",
    "\n",
    "Now that we understand what agents are and have imported the necessary modules, let's begin by creating our first kernel instance and configuring the environment properly.\n",
    "\n",
    "### Creating a Kernel Instance\n",
    "\n",
    "The `Kernel` is the central orchestration component in Semantic Kernel. It manages AI services, plugins, and other resources that agents need to function. Let's now create a helper function that will configure a kernel with the appropriate AI service based on the available credentials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0262a3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_id = 'agent'\n",
    "def create_kernel_with_service(service_id):\n",
    "    kernel = sk.Kernel()\n",
    "    kernel.add_service(\n",
    "        AzureChatCompletion(\n",
    "            service_id=service_id,\n",
    "            deployment_name=os.getenv(\"AZURE_OPENAI_MODEL_DEPLOYMENT_NAME\"),\n",
    "            api_key=os.getenv('AZURE_OPENAI_API_KEY'),\n",
    "            endpoint=os.getenv('AZURE_OPENAI_ENDPOINT')\n",
    "        )\n",
    "    )\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5885f19",
   "metadata": {},
   "source": [
    "Now let's create our first kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584efa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = create_kernel_with_service(service_id=\"chat-completion\")\n",
    "print(\"Kernel created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dd3dfe",
   "metadata": {},
   "source": [
    "### Understanding Service Configuration\n",
    "\n",
    "When adding an AI service to the kernel, we specified a `service_id`. This ID is important because:\n",
    "\n",
    "1. It allows you to add multiple services to the same kernel\n",
    "2. You can selectively use different services for different agents\n",
    "3. It helps organize and identify your services\n",
    "\n",
    "If you need specific execution settings for your AI service (like temperature, top-p, or function calling behavior), you can retrieve and modify them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44efdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the execution settings for our service\n",
    "settings = kernel.get_prompt_execution_settings_from_service_id(\n",
    "    service_id=\"chat-completion\"\n",
    ")\n",
    "\n",
    "# Configure settings\n",
    "settings.temperature = 0.7\n",
    "settings.function_choice_behavior = FunctionChoiceBehavior.Auto()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a19c85",
   "metadata": {},
   "source": [
    "### Exercise: Create Multiple Services in a Kernel\n",
    "\n",
    "In this exercise, try creating a kernel with two different AI services with different configurations. This will be useful when we want to use different services for different agents or functions.\n",
    "\n",
    "Your task:\n",
    "1. Create a new kernel\n",
    "2. Add two services with different service IDs (e.g., \"creative\" and \"precise\")\n",
    "3. Configure the \"creative\" service with higher temperature (e.g., 0.8)\n",
    "4. Configure the \"precise\" service with lower temperature (e.g., 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8c480f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize your kernel\n",
    "\n",
    "# Add first service - creative with higher temperature\n",
    "\n",
    "# Add second service - precise with lower temperature\n",
    "\n",
    "# Configure the settings for each service\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc602c9e",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click to see solution</summary>\n",
    "\n",
    "    ```python\n",
    "    # Create a new kernel for multiple services\n",
    "    multi_service_kernel = sk.Kernel()\n",
    "\n",
    "    # Add first service - creative with higher temperature\n",
    "\n",
    "    multi_service_kernel.add_service(\n",
    "        AzureChatCompletion(\n",
    "            service_id=\"creative\",\n",
    "            deployment_name=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),\n",
    "            endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "            api_key=os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Add second service - precise with lower temperature\n",
    "    multi_service_kernel.add_service(\n",
    "        AzureChatCompletion(\n",
    "            service_id=\"precise\",\n",
    "            deployment_name=os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\"),\n",
    "            endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "            api_key=os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Configure the settings for each service\n",
    "    creative_settings = multi_service_kernel.get_prompt_execution_settings_from_service_id(service_id=\"creative\")\n",
    "    creative_settings.temperature = 0.8\n",
    "    print(f\"Creative service temperature: {creative_settings.temperature}\")\n",
    "\n",
    "    precise_settings = multi_service_kernel.get_prompt_execution_settings_from_service_id(service_id=\"precise\")\n",
    "    precise_settings.temperature = 0.2\n",
    "    print(f\"Precise service temperature: {precise_settings.temperature}\")\n",
    "    ```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa2ca98",
   "metadata": {},
   "source": [
    "### Key Takeaways\n",
    "\n",
    "In this section, we've learned how to:\n",
    "\n",
    "1. **Set up our environment** with necessary imports and credentials\n",
    "2. **Create a kernel** as the foundation for our agents\n",
    "3. **Configure AI services** with specific IDs and settings\n",
    "4. **Manage execution settings** to control how the AI generates responses\n",
    "\n",
    "In the next section, we'll create our first agent using the kernel we've just configured."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994f8098",
   "metadata": {},
   "source": [
    "## 3. Your First Agent: ChatCompletionAgent\n",
    "\n",
    "Now that we have our kernel and services set up, let's create our first agent. We'll start with the `ChatCompletionAgent`, which is a simple yet powerful agent that leverages the chat completion capabilities of large language models.\n",
    "\n",
    "### Creating a Basic Agent\n",
    "\n",
    "To create a `ChatCompletionAgent`, we need to provide:\n",
    "1. A kernel with a configured chat service\n",
    "2. Instructions that define the agent's behavior\n",
    "3. Optional parameters like a name and execution settings\n",
    "\n",
    "Let's create a simple assistant agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86e9b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple assistant agent\n",
    "assistant_agent = ChatCompletionAgent(\n",
    "    kernel=kernel,\n",
    "    name=\"Assistant\",\n",
    "    instructions=\"You are a helpful assistant that provides concise and accurate information. Keep your responses brief but informative.\",\n",
    ")\n",
    "\n",
    "print(f\"Agent '{assistant_agent.name}' created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d54dc8",
   "metadata": {},
   "source": [
    "### Configuring Instructions and Parameters\n",
    "\n",
    "The `instructions` parameter is crucial as it defines how your agent will behave. Think of it as the \"system prompt\" that shapes the agent's personality, capabilities, and limitations. Let's explore some more complex instructions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a989b2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "math_tutor_agent = ChatCompletionAgent(\n",
    "    kernel=kernel,\n",
    "    name=\"MathTutor\",\n",
    "    instructions=\"\"\"You are a math tutor specialized in helping students understand mathematical concepts.\n",
    "    \n",
    "    When responding to questions:\n",
    "    1. First explain the underlying concept in simple terms\n",
    "    2. Then walk through the solution step by step\n",
    "    3. Provide a simple example to reinforce the learning\n",
    "    4. Avoid solving problems directly without explanation\n",
    "    \n",
    "    Always be encouraging and patient.\n",
    "    \"\"\",\n",
    ")\n",
    "\n",
    "print(f\"Agent '{math_tutor_agent.name}' created with specialized instructions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829908a6",
   "metadata": {},
   "source": [
    "### Understanding Agent Execution\n",
    "\n",
    "Once an agent is created, it needs a chat history to interact with. The chat history maintains the state of the conversation and provides context for the agent's responses.\n",
    "\n",
    "Here's a simple example of how to execute an agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828ef40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a chat history to maintain conversation state\n",
    "chat_history = ChatHistory()\n",
    "\n",
    "# Add a user message to the chat history\n",
    "chat_history.add_message(\n",
    "    ChatMessageContent(\n",
    "        role=AuthorRole.USER, content=\"Hello! Can you introduce yourself?\"\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# Define a function to execute the agent asynchronously\n",
    "async def get_agent_response(agent, history):\n",
    "    # Get a single response from the agent\n",
    "    response = await agent.get_response(messages=history)\n",
    "    return response\n",
    "\n",
    "\n",
    "# Execute the agent\n",
    "response = await get_agent_response(assistant_agent, chat_history)\n",
    "\n",
    "# Print the agent's response\n",
    "print(f\"Agent: {response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55322e73",
   "metadata": {},
   "source": [
    "There are actually three main ways to invoke an agent:\n",
    "\n",
    "1. **`get_response()`**: Returns a single response directly as a `ChatMessageContent` object\n",
    "2. **`invoke()`**: Returns an async iterable of `ChatMessageContent` objects\n",
    "3. **`invoke_stream()`**: Streams the response in real-time (useful for long responses)\n",
    "\n",
    "Let's see how `invoke()` works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2a5aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new chat history\n",
    "chat_history = ChatHistory()\n",
    "chat_history.add_message(\n",
    "    ChatMessageContent(\n",
    "        role=AuthorRole.USER, content=\"What can you tell me about quantum computing?\"\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# Define a function to invoke the agent using invoke()\n",
    "async def invoke_agent(agent, history):\n",
    "    responses = []\n",
    "    # Iterate through the responses asynchronously\n",
    "    async for response in agent.invoke(messages=history):\n",
    "        responses.append(response)\n",
    "    return responses\n",
    "\n",
    "\n",
    "# Execute the agent\n",
    "responses = await invoke_agent(assistant_agent, chat_history)\n",
    "\n",
    "# Print the responses\n",
    "for i, response in enumerate(responses):\n",
    "    # Access the message content correctly through the AgentResponseItem\n",
    "    message_text = response.message.content\n",
    "    print(f\"Response {i + 1}: {message_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5cce99",
   "metadata": {},
   "source": [
    "### Exercise: Implement a Simple Question-Answering Agent\n",
    "\n",
    "Now it's your turn to create a custom agent. Implement a question-answering agent that specializes in providing factual information about a specific topic of your choice.\n",
    "\n",
    "Your task:\n",
    "1. Create a new `ChatCompletionAgent` with a descriptive name\n",
    "2. Configure it with detailed instructions that define its area of expertise and how it should respond\n",
    "3. Create a chat history with a relevant question\n",
    "4. Execute the agent and display its response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6efbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here to create and execute a question-answering agent\n",
    "\n",
    "# 1. Create your agent with specialized instructions\n",
    "\n",
    "# 2. Create a chat history with a relevant question\n",
    "\n",
    "# 3. Execute the agent and get its response\n",
    "\n",
    "# 4. Print the response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449bcc3d",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click to see solution</summary>\n",
    "\n",
    "```python\n",
    "# Create a specialized space expert agent with detailed instructions\n",
    "space_expert_agent = ChatCompletionAgent(\n",
    "    kernel=kernel,\n",
    "    name=\"SpaceExpert\",\n",
    "    instructions=\"\"\"You are an expert in astronomy and space exploration.\n",
    "    \n",
    "    When answering questions:\n",
    "    - Provide factual, scientifically accurate information\n",
    "    - Include relevant dates, measurements, and statistics when applicable\n",
    "    - Explain complex concepts in accessible language\n",
    "    - Differentiate between established facts and theoretical or speculative ideas\n",
    "    - When appropriate, mention recent developments or missions\n",
    "    \n",
    "    Focus on being educational and inspiring curiosity about space.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Create a chat history with a specific astronomy question\n",
    "space_chat = ChatHistory()\n",
    "space_chat.add_message(ChatMessageContent(\n",
    "    role=AuthorRole.USER, \n",
    "    content=\"What are exoplanets and how do scientists detect them?\"\n",
    "))\n",
    "\n",
    "# Helper function to get the agent's response\n",
    "async def get_expert_response(agent, history):\n",
    "    response = await agent.get_response(messages=history)\n",
    "    return response\n",
    "\n",
    "# Execute the agent and get its response\n",
    "space_response = await get_expert_response(agent=space_expert_agent, history=space_chat)\n",
    "\n",
    "# Display the agent's response\n",
    "print(f\"SpaceExpert: {space_response.content}\")\n",
    "```\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
